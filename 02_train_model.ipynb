{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from parse_preprocessed_data import get_inputs_and_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 200\n",
    "\n",
    "hidden_size = 128\n",
    "learning_rate = 2e-3\n",
    "dropout = 0.5\n",
    "batch_size = 100\n",
    "num_layers = 3\n",
    "max_epochs = 20\n",
    "\n",
    "early_stopping = True\n",
    "patience = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique chars: ['\\n', '-', '<', '>', '?', 'B', 'E', 'Q', 'S', 'X', '[', ']', 'b', 'o', 'x']\n",
      "Number of unique chars: 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(15, (119150, 200, 15), (119150, 200))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ix, ix_to_char, vocab_size, inputs, targets = get_inputs_and_targets('data_preprocessed/mario.txt', seq_length)\n",
    "vocab_size, inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_valid, y_train, y_valid = train_test_split(inputs, targets, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_three_cols = inputs[0][:3 * 17]\n",
    "np.savetxt('data_preprocessed/seed.txt', first_three_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_preprocessed/char_to_ix.json', 'w+') as json_f:\n",
    "    json.dump(char_to_ix, json_f)\n",
    "\n",
    "with open('data_preprocessed/ix_to_char.json', 'w+') as json_f:\n",
    "    json.dump(ix_to_char, json_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = EarlyStopping(\n",
    "    monitor='val_out_acc_custom_acc', mode='max', patience=patience, restore_best_weights=early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    return scce(\n",
    "        tf.reshape(y_true, shape=(tf.shape(y_true)[0] * seq_length, )), \n",
    "        tf.reshape(y_pred, shape=(tf.shape(y_pred)[0] * seq_length, vocab_size))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(\n",
    "        tf.cast(\n",
    "            tf.math.equal(\n",
    "                tf.math.argmax(tf.reshape(y_pred, shape=(tf.shape(y_pred)[0] * seq_length, vocab_size)), axis=-1), \n",
    "                tf.cast(tf.reshape(y_true, shape=(tf.shape(y_true)[0] * seq_length, )), dtype=tf.int64)\n",
    "            ), \n",
    "            dtype=tf.float32\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_1_state_h_in = keras.layers.Input(shape=[hidden_size])\n",
    "lstm_1_state_c_in = keras.layers.Input(shape=[hidden_size])\n",
    "\n",
    "lstm_2_state_h_in = keras.layers.Input(shape=[hidden_size])\n",
    "lstm_2_state_c_in = keras.layers.Input(shape=[hidden_size])\n",
    "\n",
    "lstm_3_state_h_in = keras.layers.Input(shape=[hidden_size])\n",
    "lstm_3_state_c_in = keras.layers.Input(shape=[hidden_size])\n",
    "\n",
    "input = keras.layers.Input(shape=[seq_length, vocab_size])\n",
    "\n",
    "out, lstm_1_state_h_out, lstm_1_state_c_out = keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True)(\n",
    "    input, initial_state=[lstm_1_state_h_in, lstm_1_state_c_in]\n",
    ")\n",
    "out = layers.Dropout(dropout)(out)\n",
    "\n",
    "out, lstm_2_state_h_out, lstm_2_state_c_out = keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True)(\n",
    "    out, initial_state=[lstm_2_state_h_in, lstm_2_state_c_in]\n",
    ")\n",
    "out = layers.Dropout(dropout)(out)\n",
    "\n",
    "out, lstm_3_state_h_out, lstm_3_state_c_out = keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True)(\n",
    "    out, initial_state=[lstm_3_state_h_in, lstm_3_state_c_in]\n",
    ")\n",
    "out = layers.Dropout(dropout)(out)\n",
    "\n",
    "out = layers.Dense(vocab_size)(out)\n",
    "out = layers.Activation('softmax')(out)\n",
    "\n",
    "out_acc = layers.Lambda(lambda x:x, name = \"out_acc\")(out)\n",
    "\n",
    "model = keras.models.Model(\n",
    "    inputs=[\n",
    "        input, \n",
    "        lstm_1_state_h_in, lstm_1_state_c_in,\n",
    "        lstm_2_state_h_in, lstm_2_state_c_in,\n",
    "        lstm_3_state_h_in, lstm_3_state_c_in\n",
    "    ], \n",
    "    outputs=[\n",
    "        out_acc,\n",
    "        lstm_1_state_h_out, lstm_1_state_c_out,\n",
    "        lstm_2_state_h_out, lstm_2_state_c_out,\n",
    "        lstm_3_state_h_out, lstm_3_state_c_out\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=[custom_loss, None, None, None, None, None, None], \n",
    "    loss_weights=[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    metrics={'out_acc':custom_acc},\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_ixs = []\n",
    "# ix = 100\n",
    "# while True:\n",
    "#     split_ixs.append(ix)\n",
    "#     ix += batch_size\n",
    "#     if ix >= len(x_train):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(split_ixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_random_ixs_for_batches():\n",
    "#     return np.split(np.random.choice(np.arange(len(x_train)), size=len(x_train), replace=False), split_ixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train():\n",
    "\n",
    "#     print('Preparing ...')\n",
    "\n",
    "#     last_valid_acc = 0\n",
    "    \n",
    "#     patience_used = 0\n",
    "\n",
    "#     for epoch in range(max_epochs):\n",
    "\n",
    "#         random_ixs_for_batches = get_random_ixs_for_batches()\n",
    "#         for i, ixs_for_one_batch in enumerate(random_ixs_for_batches):\n",
    "\n",
    "#             xb, yb = x_train[ixs_for_one_batch], y_train[ixs_for_one_batch]\n",
    "#             dummy = np.zeros((len(ixs_for_one_batch), hidden_size))\n",
    "\n",
    "#             train_metrics_dict = model.train_on_batch(\n",
    "#                 x=[xb, dummy, dummy, dummy, dummy, dummy, dummy], \n",
    "#                 y=[yb, dummy, dummy, dummy, dummy, dummy, dummy], \n",
    "#                 return_dict=True\n",
    "#             )\n",
    "\n",
    "#             loss = train_metrics_dict['loss']\n",
    "#             acc = train_metrics_dict['out_acc_custom_acc']\n",
    "\n",
    "#             print(f'Epoch {epoch + 1:>2} / {max_epochs} | Batch {i+1:>3} / {len(random_ixs_for_batches)} | Train Loss {round(loss, 3):>5} | Train Acc {round(acc, 3):>5}')\n",
    "\n",
    "#             if acc > 0.9:\n",
    "            \n",
    "#                 if (i+1) % validation_freq == 0:\n",
    "\n",
    "#                     dummy = np.zeros((len(x_valid), hidden_size))\n",
    "\n",
    "#                     valid_metrics_dict = model.evaluate(\n",
    "#                         x=[x_valid, dummy, dummy, dummy, dummy, dummy, dummy], \n",
    "#                         y=[y_valid, dummy, dummy, dummy, dummy, dummy, dummy], \n",
    "#                         batch_size=100, return_dict=True, verbose=1\n",
    "#                     )\n",
    "                    \n",
    "#                     del dummy\n",
    "\n",
    "#                     valid_acc = valid_metrics_dict['out_acc_custom_acc']\n",
    "\n",
    "#                     if valid_acc < last_valid_acc:\n",
    "\n",
    "#                         if patience_used < max_patience - 1:\n",
    "#                             patience_used += 1\n",
    "#                         else:\n",
    "#                             return\n",
    "\n",
    "#                     else:\n",
    "#                         model.save(f'trained_models/mario_lstm.h5')\n",
    "#                         last_valid_acc = valid_acc\n",
    "#                         patience_used = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(f'trained_models/mario_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1073/1073 [==============================] - 149s 139ms/step - loss: 0.4140 - out_acc_loss: 0.4140 - out_acc_custom_acc: 0.8775 - val_loss: 0.3675 - val_out_acc_loss: 0.3675 - val_out_acc_custom_acc: 0.8920\n",
      "Epoch 2/20\n",
      "1073/1073 [==============================] - 147s 137ms/step - loss: 0.1927 - out_acc_loss: 0.1927 - out_acc_custom_acc: 0.9427 - val_loss: 0.3713 - val_out_acc_loss: 0.3713 - val_out_acc_custom_acc: 0.9001\n",
      "Epoch 3/20\n",
      "1073/1073 [==============================] - 146s 136ms/step - loss: 0.1564 - out_acc_loss: 0.1564 - out_acc_custom_acc: 0.9530 - val_loss: 0.3754 - val_out_acc_loss: 0.3754 - val_out_acc_custom_acc: 0.9131\n",
      "Epoch 4/20\n",
      "1073/1073 [==============================] - 147s 137ms/step - loss: 0.1369 - out_acc_loss: 0.1369 - out_acc_custom_acc: 0.9584 - val_loss: 0.4401 - val_out_acc_loss: 0.4401 - val_out_acc_custom_acc: 0.9128\n",
      "Epoch 5/20\n",
      "1073/1073 [==============================] - 146s 136ms/step - loss: 0.1236 - out_acc_loss: 0.1236 - out_acc_custom_acc: 0.9621 - val_loss: 0.4747 - val_out_acc_loss: 0.4747 - val_out_acc_custom_acc: 0.9080\n",
      "Epoch 6/20\n",
      "1073/1073 [==============================] - 146s 136ms/step - loss: 0.1137 - out_acc_loss: 0.1137 - out_acc_custom_acc: 0.9649 - val_loss: 0.5405 - val_out_acc_loss: 0.5405 - val_out_acc_custom_acc: 0.9082\n",
      "Epoch 7/20\n",
      "1073/1073 [==============================] - 147s 137ms/step - loss: 0.1068 - out_acc_loss: 0.1068 - out_acc_custom_acc: 0.9668 - val_loss: 0.5654 - val_out_acc_loss: 0.5654 - val_out_acc_custom_acc: 0.9067\n",
      "Epoch 8/20\n",
      "1073/1073 [==============================] - 147s 137ms/step - loss: 0.1012 - out_acc_loss: 0.1012 - out_acc_custom_acc: 0.9684 - val_loss: 0.5976 - val_out_acc_loss: 0.5976 - val_out_acc_custom_acc: 0.9041\n",
      "Epoch 9/20\n",
      "1073/1073 [==============================] - 146s 136ms/step - loss: 0.0972 - out_acc_loss: 0.0972 - out_acc_custom_acc: 0.9695 - val_loss: 0.6048 - val_out_acc_loss: 0.6048 - val_out_acc_custom_acc: 0.9012\n",
      "Epoch 10/20\n",
      "1073/1073 [==============================] - 147s 137ms/step - loss: 0.0938 - out_acc_loss: 0.0938 - out_acc_custom_acc: 0.9705 - val_loss: 0.6807 - val_out_acc_loss: 0.6807 - val_out_acc_custom_acc: 0.8984\n",
      "Epoch 11/20\n",
      "1073/1073 [==============================] - 147s 137ms/step - loss: 0.0912 - out_acc_loss: 0.0912 - out_acc_custom_acc: 0.9712 - val_loss: 0.6457 - val_out_acc_loss: 0.6457 - val_out_acc_custom_acc: 0.9008\n",
      "Epoch 12/20\n",
      "1073/1073 [==============================] - 147s 137ms/step - loss: 0.0889 - out_acc_loss: 0.0889 - out_acc_custom_acc: 0.9719 - val_loss: 0.6501 - val_out_acc_loss: 0.6501 - val_out_acc_custom_acc: 0.9006\n",
      "Epoch 13/20\n",
      "1073/1073 [==============================] - 147s 137ms/step - loss: 0.0871 - out_acc_loss: 0.0871 - out_acc_custom_acc: 0.9724 - val_loss: 0.6883 - val_out_acc_loss: 0.6883 - val_out_acc_custom_acc: 0.9026\n",
      "Epoch 14/20\n",
      "1073/1073 [==============================] - 147s 137ms/step - loss: 0.0854 - out_acc_loss: 0.0854 - out_acc_custom_acc: 0.9729 - val_loss: 0.7011 - val_out_acc_loss: 0.7011 - val_out_acc_custom_acc: 0.9035\n",
      "Epoch 15/20\n",
      "1073/1073 [==============================] - 147s 137ms/step - loss: 0.0840 - out_acc_loss: 0.0840 - out_acc_custom_acc: 0.9733 - val_loss: 0.7074 - val_out_acc_loss: 0.7074 - val_out_acc_custom_acc: 0.8996\n",
      "Epoch 16/20\n",
      "1073/1073 [==============================] - 146s 137ms/step - loss: 0.0828 - out_acc_loss: 0.0828 - out_acc_custom_acc: 0.9737 - val_loss: 0.7346 - val_out_acc_loss: 0.7346 - val_out_acc_custom_acc: 0.9013\n",
      "Epoch 17/20\n",
      "1073/1073 [==============================] - 147s 137ms/step - loss: 0.0818 - out_acc_loss: 0.0818 - out_acc_custom_acc: 0.9740 - val_loss: 0.7170 - val_out_acc_loss: 0.7170 - val_out_acc_custom_acc: 0.9009\n",
      "Epoch 18/20\n",
      "1073/1073 [==============================] - 147s 137ms/step - loss: 0.0809 - out_acc_loss: 0.0809 - out_acc_custom_acc: 0.9742 - val_loss: 0.7008 - val_out_acc_loss: 0.7008 - val_out_acc_custom_acc: 0.9000\n",
      "Epoch 19/20\n",
      "1073/1073 [==============================] - 147s 137ms/step - loss: 0.0800 - out_acc_loss: 0.0800 - out_acc_custom_acc: 0.9745 - val_loss: 0.7260 - val_out_acc_loss: 0.7260 - val_out_acc_custom_acc: 0.9006\n",
      "Epoch 20/20\n",
      "1073/1073 [==============================] - 147s 137ms/step - loss: 0.0792 - out_acc_loss: 0.0792 - out_acc_custom_acc: 0.9747 - val_loss: 0.7223 - val_out_acc_loss: 0.7223 - val_out_acc_custom_acc: 0.8992\n"
     ]
    }
   ],
   "source": [
    "dummy = np.zeros((len(inputs), hidden_size))\n",
    "history = model.fit(\n",
    "    [inputs, dummy, dummy, dummy, dummy, dummy, dummy], \n",
    "    [targets, dummy, dummy, dummy, dummy, dummy, dummy], \n",
    "    batch_size=batch_size,\n",
    "    validation_split=validation_prop,\n",
    "    shuffle=True,\n",
    "    epochs=max_epochs, \n",
    "    callbacks=[es_callback]\n",
    ")\n",
    "model.save('trained_models/mario_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
